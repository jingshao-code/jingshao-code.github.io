---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

## üëã Hey there! I'm Jing Shao.

I'm a graduate student in **Computer Software Engineering** at [**Northeastern University ‚Äì College of Engineering**](https://coe.northeastern.edu/), specializing in **machine learning**, **multi-modal model safety**, and **end-to-end AI system development**.

My research focuses on **AI safety** and **robustness**. I've explored **audio-based jailbreak attacks** on **LALMs**, developed **World Models** for **humanoid robot planning**, and evaluated **safety** in **VLA systems** for real-world deployment.

Beyond academia, I contributed to a **stealth-stage AI startup**, developing **AI-powered audio systems** and integrating **ML models** into scalable infrastructure for **real-time interaction**. I'm also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration** for the open-source community.

My research interests center on **embodied AI**, **VLA systems**, and their **safe real-world applications**, to build **human-centered, trustworthy intelligent systems**.


## üìå I‚Äôm actively seeking a Fall 2025 internship or full-time roles in Machine Learning Engineering, Robotics, Applied AI, or Software Development.

‚ú® [My CV can be found here!](http://jingshao-code.github.io) 
Feel free to reach out or connect!!



# üî• News
- **May 2025** ‚Äî üéâ Awarded the **AWS re:Inforce 2025 Grant** for my work in AI safety research.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2025</div><img src='images/nips.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772)

Hao Cheng, Erjia Xiao, **Jing Shao**, Yichi Wang, Le Yang, Chao Shen, Philip Torr, Jindong Gu, Renjing Xu

<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->

- **Academic Impact**: This work introduces Jailbreak-AudioBench, the first comprehensive benchmark for evaluating audio-based jailbreak threats against LALMs. By systematically exploiting audio-specific hidden semantics‚Äîsuch as tone, intonation, background noise, and emotion‚Äîwe uncover previously unreported vulnerabilities in multimodal AI safety. This research lays the foundation for future work in understanding and defending against audio manipulation attacks in LALMs.
- **Practical Impact**: Our benchmark reveals critical security vulnerabilities in state-of-the-art LALMs, with models like SALMONN-7B reaching an 85.1% Attack Success Rate under systematic query-based attacks. These findings have direct implications for real-world systems, including voice assistants, customer service bots, and in-vehicle audio interfaces, offering actionable guidance for building safer and more robust audio AI systems.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MobiCom 2024</div><img src='images/mobicom.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Energy-based Active Learning for Bringing Beam-induced Domain Gap for 3D Object Detection](https://dl.acm.org/doi/abs/10.1145/3636534.3694723)

Le Yang, Yixuan Yan, **Jing Shao**, Hao Cheng, Fan Li

<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->

- **Academic Impact**: This work proposes an energy-based active learning framework to close the domain gap between 64-beam and 16-beam LiDARs, enabling knowledge transfer with minimal labeled data.
- **Practical Impact**: Our method significantly reduces annotation cost and achieves high-performance 3D object detection on 16-beam LiDAR with only a small portion of labeled samples.
</div>
</div>


# üéñ Honors and Awards
- *May 2025*, Awarded **AWS All Builders Welcome Grant** re:Inforce.
- *May 2025*, GSoC 2025 Contributor & **Flutter Organization Member**.
- *Sep 2024*, Awarded **AWS All Builders Welcome Grant** re:Invent.

# üìñ Educations
- *Jan 2024 ‚Äì Apr 2026*, M.S., Computer Software Engineering, Northeastern University.

# üì£ Talks and Conferences
- *Jun 2025*, Attending **AWS re:Inforce 2025**, Philadelphia.
- *Dec 2024*, Attending **AWS re:Invent 2024**, Las Vegas.  
- *Oct 2024*, Presenting research at **MobiCom 2024**, Washington D.C. 

# üíª Internships
- *May 2025 ‚Äì Present*, [Google Summer of Code](https://summerofcode.withgoogle.com/), Software Developer.
- *Jan 2025 ‚Äì Present*, Stealth AI Startup, Machine Learning Engineer.
- *Sep 2024 ‚Äì May 2025*, [The Hong Kong University of Science and Technology](https://hkust.edu.hk), Research Assistant.
- *May 2024 ‚Äì Sep 2024*, [X-Humanoid](https://x-humanoid.com/), Machine Learning Engineer.

