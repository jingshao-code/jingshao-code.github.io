{
    "sourceFile": "_pages/about.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1756470853405,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1756471118031,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,9 @@\n \n Beyond academia, I contributed to a **stealth-stage AI startup**, developing **AI-powered audio systems** and integrating **ML models** into scalable infrastructure for **real-time interaction**. I'm also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration** for the open-source community.\n \n \n-## ğŸ“Œ Iâ€™m actively seeking a Fall 2025 internship or full-time roles in Machine Learning Engineering, Robotics, Applied AI.\n+## ğŸ“Œ I'm actively seeking Research Assistant and PhD positions.\n \n âœ¨ [My CV can be found here!](http://jingshao-code.github.io) \n Feel free to reach out or connect!!\n \n"
                },
                {
                    "date": 1756471251118,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,9 +33,9 @@\n \n \n \n # ğŸ”¥ News\n-- *Aug 2025* â€” ğŸ‰ Awarded the **AWS re:Inforce 2025 Grant** for my work in AI safety research.\n+- *Aug 2025* â€” ğŸ‰ Selected as a **Mentor** for **AWS re:Invent 2025**, mentoring 10 ABW Grant participants.\n - *May 2025* â€” ğŸ‰ Awarded the **AWS re:Inforce 2025 Grant** for my work in AI safety research.\n - *May 2025* â€” ğŸ‰ Selected as a **Google Summer of Code** 2025 Contributor. \n \n # ğŸ“ Publications \n"
                },
                {
                    "date": 1756472753988,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,25 +20,17 @@\n ## ğŸ‘‹ Hey there! I'm Jing Shao.\n \n I'm a graduate student in **Computer Software Engineering** at [**Northeastern University â€“ College of Engineering**](https://coe.northeastern.edu/), specializing in **machine learning**, **multi-modal model safety**, and **end-to-end AI system development**.\n \n-<<<<<<< HEAD\n-My research focuses on making generative and embodied AI systems more trustworthy, robust, and efficient, aiming for reliable performance in real-world scenarios.\n+My research focuses on making generative and embodied AI systems more trustworthy, robust, and efficient, aiming for reliable performance in real-world scenarios\n \n Beyond academia, I contributed to a **stealth-stage AI startup**, developing **AI-powered audio systems** and integrating **ML models** into scalable infrastructure for **real-time interaction**. I'm also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration** for the open-source community.\n \n+My research interests center on **embodied AI**, **VLA systems**, and their **safe real-world applications**, to build **human-centered, trustworthy intelligent systems**.\n \n-## ğŸ“Œ I'm actively seeking Research Assistant and PhD positions.\n-=======\n-My research focuses on **making generative and embodied AI systems more trustworthy, robust, and efficient, aiming for reliable performance in real-world scenarios**\n \n-Beyond academia, I contributed to a **stealth-stage AI startup**, developing **AI-powered audio systems** and integrating **ML models** into scalable infrastructure for **real-time interaction**. I'm also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration** for the open-source community.\n+## ğŸ“Œ Iâ€™m actively seeking a Fall 2025 internship or full-time roles in Machine Learning Engineering, Robotics, Applied AI, or Software Development.\n \n-**ğŸ“Œ Actively seeking opportunities in:**\n-- **Industry**: Fall 2025 internship or full-time roles in ML Engineering/Applied AI.\n-- **Academia**: Research Assistant positions or Fall 2026 PhD programs.\n->>>>>>> 873ce76706c83817abc6de22b6e89ad6f28cfa8e\n-\n âœ¨ [My CV can be found here!](http://jingshao-code.github.io) \n Feel free to reach out or connect!!\n \n \n"
                },
                {
                    "date": 1758352028940,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,102 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+## ğŸ‘‹ Hey there! I'm Jing Shao.\n+\n+I'm a graduate student in **Computer Software Engineering** at [**Northeastern University â€“ College of Engineering**](https://coe.northeastern.edu/), specializing in **machine learning**, **multi-modal model safety**, and **end-to-end AI system development**.\n+\n+My research focuses on **making generative and embodied AI systems more trustworthy, robust, and efficient, aiming for reliable performance in real-world scenarios**.\n+\n+Beyond academia, I contributed to a **stealth-stage AI startup**, developing **AI-powered audio systems** and integrating **ML models** into scalable infrastructure for **real-time interaction**. I'm also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration** for the open-source community.\n+\n+\n+## ğŸ“Œ Iâ€™m actively seeking Research Assistant and PhD position.\n+\n+âœ¨ [My CV can be found here!](http://jingshao-code.github.io) \n+Feel free to reach out or connect!!\n+\n+\n+\n+# ğŸ”¥ News\n+- *Aug 2025* â€” ğŸ‰ Selected as a **Mentor** for **AWS re:Invent 2025**, mentoring 10 ABW Grant participants.\n+- *May 2025* â€” ğŸ‰ Awarded the **AWS re:Inforce 2025 Grant** for my work in AI safety research.\n+- *May 2025* â€” ğŸ‰ Selected as a **Google Summer of Code** 2025 Contributor. \n+\n+# ğŸ“ Publications \n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">NeurIPS 2025</div><img src='images/nips.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772)\n+\n+Hao Cheng, Erjia Xiao, **Jing Shao**, Yichi Wang, Le Yang, Chao Shen, Philip Torr, Jindong Gu, Renjing Xu\n+\n+<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->\n+\n+- **Academic Impact**: This work introduces Jailbreak-AudioBench, the first comprehensive benchmark for evaluating audio-based jailbreak threats against LALMs. By systematically exploiting audio-specific hidden semanticsâ€”such as tone, intonation, background noise, and emotionâ€”we uncover previously unreported vulnerabilities in multimodal AI safety. This research lays the foundation for future work in understanding and defending against audio manipulation attacks in LALMs.\n+- **Practical Impact**: Our benchmark reveals critical security vulnerabilities in state-of-the-art LALMs, with models like SALMONN-7B reaching an 85.1% Attack Success Rate under systematic query-based attacks. These findings have direct implications for real-world systems, including voice assistants, customer service bots, and in-vehicle audio interfaces, offering actionable guidance for building safer and more robust audio AI systems.\n+</div>\n+</div>\n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MobiCom 2024</div><img src='images/mobicom.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Energy-based Active Learning for Bringing Beam-induced Domain Gap for 3D Object Detection](https://dl.acm.org/doi/abs/10.1145/3636534.3694723)\n+\n+Le Yang, Yixuan Yan, **Jing Shao**, Hao Cheng, Fan Li\n+\n+<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->\n+\n+- **Academic Impact**: This work proposes an energy-based active learning framework to close the domain gap between 64-beam and 16-beam LiDARs, enabling knowledge transfer with minimal labeled data.\n+- **Practical Impact**: Our method significantly reduces annotation cost and achieves high-performance 3D object detection on 16-beam LiDAR with only a small portion of labeled samples.\n+</div>\n+</div>\n+\n+\n+# ğŸ– Honors and Awards\n+- *May 2025*, Awarded **AWS All Builders Welcome Grant** re:Inforce.\n+- *May 2025*, GSoC 2025 Contributor & **Flutter Organization Member**.\n+- *Sep 2024*, Awarded **AWS All Builders Welcome Grant** re:Invent.\n+\n+# ğŸ“– Educations\n+- *Jan 2024 â€“ Apr 2026*, M.S., Computer Software Engineering, Northeastern University.\n+\n+# ğŸ“£ Talks and Conferences\n+- *Jun 2025*, Attending **AWS re:Inforce 2025**, Philadelphia.\n+- *Dec 2024*, Attending **AWS re:Invent 2024**, Las Vegas.  \n+- *Oct 2024*, Presenting research at **MobiCom 2024**, Washington D.C. \n+\n+# ğŸ’» Internships\n+- *May 2025 â€“ Present*, [Google Summer of Code](https://summerofcode.withgoogle.com/), Software Developer.\n+- *Jan 2025 â€“ Present*, Stealth AI Startup, Machine Learning Engineer.\n+- *Sep 2024 â€“ May 2025*, [The Hong Kong University of Science and Technology](https://hkust.edu.hk), Research Assistant.\n+- *May 2024 â€“ Sep 2024*, [X-Humanoid](https://x-humanoid.com/), Machine Learning Engineer.\n+\n+# ğŸ“ Blogs\n+\n+I write about my journey in tech and my thoughts in life! \n+\n+[**View all blog posts â†’**](/blogs/)\n+\n"
                }
            ],
            "date": 1756470853405,
            "name": "Commit-0",
            "content": "---\npermalink: /\ntitle: \"\"\nexcerpt: \"\"\nauthor_profile: true\nredirect_from: \n  - /about/\n  - /about.html\n---\n\n{% if site.google_scholar_stats_use_cdn %}\n{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n{% else %}\n{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n{% endif %}\n{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n\n<span class='anchor' id='about-me'></span>\n\n## ğŸ‘‹ Hey there! I'm Jing Shao.\n\nI'm a graduate student in **Computer Software Engineering** at [**Northeastern University â€“ College of Engineering**](https://coe.northeastern.edu/), specializing in **machine learning**, **multi-modal model safety**, and **end-to-end AI system development**.\n\nMy research focuses on making generative and embodied AI systems more trustworthy, robust, and efficient, aiming for reliable performance in real-world scenarios.\n\nBeyond academia, I contributed to a **stealth-stage AI startup**, developing **AI-powered audio systems** and integrating **ML models** into scalable infrastructure for **real-time interaction**. I'm also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration** for the open-source community.\n\n\n## ğŸ“Œ Iâ€™m actively seeking a Fall 2025 internship or full-time roles in Machine Learning Engineering, Robotics, Applied AI.\n\nâœ¨ [My CV can be found here!](http://jingshao-code.github.io) \nFeel free to reach out or connect!!\n\n\n\n# ğŸ”¥ News\n- *Aug 2025* â€” ğŸ‰ Awarded the **AWS re:Inforce 2025 Grant** for my work in AI safety research.\n- *May 2025* â€” ğŸ‰ Awarded the **AWS re:Inforce 2025 Grant** for my work in AI safety research.\n- *May 2025* â€” ğŸ‰ Selected as a **Google Summer of Code** 2025 Contributor. \n\n# ğŸ“ Publications \n\n<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">Arxiv 2025</div><img src='images/nips.png' alt=\"sym\" width=\"100%\"></div></div>\n<div class='paper-box-text' markdown=\"1\">\n\n[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772)\n\nHao Cheng, Erjia Xiao, **Jing Shao**, Yichi Wang, Le Yang, Chao Shen, Philip Torr, Jindong Gu, Renjing Xu\n\n<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->\n\n- **Academic Impact**: This work introduces Jailbreak-AudioBench, the first comprehensive benchmark for evaluating audio-based jailbreak threats against LALMs. By systematically exploiting audio-specific hidden semanticsâ€”such as tone, intonation, background noise, and emotionâ€”we uncover previously unreported vulnerabilities in multimodal AI safety. This research lays the foundation for future work in understanding and defending against audio manipulation attacks in LALMs.\n- **Practical Impact**: Our benchmark reveals critical security vulnerabilities in state-of-the-art LALMs, with models like SALMONN-7B reaching an 85.1% Attack Success Rate under systematic query-based attacks. These findings have direct implications for real-world systems, including voice assistants, customer service bots, and in-vehicle audio interfaces, offering actionable guidance for building safer and more robust audio AI systems.\n</div>\n</div>\n\n<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">MobiCom 2024</div><img src='images/mobicom.jpg' alt=\"sym\" width=\"100%\"></div></div>\n<div class='paper-box-text' markdown=\"1\">\n\n[Energy-based Active Learning for Bringing Beam-induced Domain Gap for 3D Object Detection](https://dl.acm.org/doi/abs/10.1145/3636534.3694723)\n\nLe Yang, Yixuan Yan, **Jing Shao**, Hao Cheng, Fan Li\n\n<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->\n\n- **Academic Impact**: This work proposes an energy-based active learning framework to close the domain gap between 64-beam and 16-beam LiDARs, enabling knowledge transfer with minimal labeled data.\n- **Practical Impact**: Our method significantly reduces annotation cost and achieves high-performance 3D object detection on 16-beam LiDAR with only a small portion of labeled samples.\n</div>\n</div>\n\n\n# ğŸ– Honors and Awards\n- *May 2025*, Awarded **AWS All Builders Welcome Grant** re:Inforce.\n- *May 2025*, GSoC 2025 Contributor & **Flutter Organization Member**.\n- *Sep 2024*, Awarded **AWS All Builders Welcome Grant** re:Invent.\n\n# ğŸ“– Educations\n- *Jan 2024 â€“ Apr 2026*, M.S., Computer Software Engineering, Northeastern University.\n\n# ğŸ“£ Talks and Conferences\n- *Jun 2025*, Attending **AWS re:Inforce 2025**, Philadelphia.\n- *Dec 2024*, Attending **AWS re:Invent 2024**, Las Vegas.  \n- *Oct 2024*, Presenting research at **MobiCom 2024**, Washington D.C. \n\n# ğŸ’» Internships\n- *May 2025 â€“ Present*, [Google Summer of Code](https://summerofcode.withgoogle.com/), Software Developer.\n- *Jan 2025 â€“ Present*, Stealth AI Startup, Machine Learning Engineer.\n- *Sep 2024 â€“ May 2025*, [The Hong Kong University of Science and Technology](https://hkust.edu.hk), Research Assistant.\n- *May 2024 â€“ Sep 2024*, [X-Humanoid](https://x-humanoid.com/), Machine Learning Engineer.\n\n# ğŸ“ Blogs\n\nI write about my journey in tech and my thoughts in life! \n\n[**View all blog posts â†’**](/blogs/)\n\n"
        }
    ]
}